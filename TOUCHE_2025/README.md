# CEDNAVâ€“UTB: Efficient Image Retrieval for Arguments with CLIP

<img src="https://github.com/user-attachments/assets/44305bf0-c24a-4c1d-8f87-852445707970" width="150" alt="Firma animada">
<img src="https://github.com/user-attachments/assets/4c167b85-1fb9-4f8d-8ef9-9e0d60cf01c7" width="250" alt="Firma animada">
<img src="https://github.com/user-attachments/assets/1658fa2f-d8a3-494f-a812-fc33cf471188" width="350" alt="Firma animada">

## Este repositorio presenta una propuesta para la participaciÃ³n del equipo **CEDNAV-UTB**, afiliado al **Centro de Desarrollo TecnolÃ³gico Naval** y la **Universidad TecnolÃ³gica de BolÃ­var**, en la tarea "Image Retrieval for Arguments" del desafÃ­o [TouchÃ© 2025](https://touche.webis.de/clef25/touche25-web/image-retrieval-for-arguments.html).



## ğŸ“Œ DescripciÃ³n

El sistema implementa una arquitectura de recuperaciÃ³n de imÃ¡genes basada en similitud semÃ¡ntica usando [CLIP (ViT-B/32)](https://openai.com/research/clip). Dado un conjunto de argumentos (claims) y un conjunto de imÃ¡genes con captions, el sistema:

1. Embebe los textos de los claims y los captions con CLIP.
2. Calcula la similitud coseno entre embeddings.
3. Recupera las 10 imÃ¡genes mÃ¡s relevantes por claim.
4. Genera un archivo `submission.jsonl` con las predicciones, conforme al formato del reto.

AdemÃ¡s, se incluye trazabilidad de huella de carbono mediante [CodeCarbon](https://mlco2.github.io/codecarbon/).



## ğŸ“ Estructura del proyecto

```bash
â”œâ”€â”€ TouchÃ©2025_V7.ipynb # Notebook principal con el pipeline completo
â”œâ”€â”€ /DATASET_TOUCHE_2025 # Carpeta en Google Drive con los datos y embeddings
â”‚ â”œâ”€â”€ touche25-image-retrieval-and-generation-main.zip
â”‚ â”œâ”€â”€ arguments.xml
â”‚ â”œâ”€â”€ claim_embeddings.pt
â”‚ â”œâ”€â”€ caption_embeddings.pt
â”‚ â””â”€â”€ submission.jsonl
```


## âš™ï¸ Requisitos

- Google Colab
- Python 3.8+
- PyTorch
- `open_clip_torch`
- `codecarbon`
- `tqdm`

InstalaciÃ³n en Colab:

```bash
!pip install open_clip_torch codecarbon tqdm
```

## ğŸš€ EjecuciÃ³n
Montar Google Drive y definir rutas

Descomprimir el dataset si no se ha hecho previamente

Cargar argumentos (arguments.xml)

Cargar captions de las imÃ¡genes usando multiprocesamiento

Configurar modelo CLIP (ViT-B/32)

Generar o cargar embeddings de claims y captions

Calcular similitud coseno y recuperar imÃ¡genes top-10

Guardar archivo de resultados en formato JSONL

Medir emisiones de carbono con CodeCarbon

## ğŸ“¤ Formato de salida
Cada lÃ­nea del archivo submission.jsonl contiene una predicciÃ³n:

```bash
{
  "argument_id": "001",
  "method": "retrieval",
  "image_id": "I1234",
  "rank": 1,
  "tag": "CEDNAV-UTB; CLIP_Baseline"
}
```

## ğŸ“Š MÃ©tricas
La evaluaciÃ³n se realiza mediante nDCG@10 sobre la correspondencia entre imÃ¡genes recuperadas y relevancia dada por anotadores humanos

## ğŸŒ± Huella de carbono
El pipeline registra el impacto ambiental estimado (emisiones de COâ‚‚ en kg) con codecarbon.

## ğŸ‘¥ Equipo
Nombre del equipo: Computer Vision UTB

AfiliaciÃ³n: CEDNAV

PaÃ­s: Colombia

Contacto: Diego Guevara

Email: hiperdaga7@gmail.com


## ğŸ“ Licencia
Este proyecto se distribuye con fines acadÃ©micos. Revisa las condiciones de uso del dataset TouchÃ© 2025 antes de su reutilizaciÃ³n.

