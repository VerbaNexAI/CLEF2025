# -*- coding: utf-8 -*-
"""Copia de Touché2025_V8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h6sgFaYkYgprq3TUjUbUZACRN4qtEx-W

<img src="https://github.com/HIPERDAGA/EO-Target-Tracking/blob/main/LOGO_CEDNAV_02.gif?raw=true" width="200">
<img src="https://github.com/HIPERDAGA/EO-Target-Tracking/blob/main/firma_animada.gif?raw=true" width="320">

#**Image Retrieval/Generation for Arguments 2025**
Team: **Computer Vision UTB**;

Affiliation: **CEDNAV**;

Country: **COLOMBIA**;

Contact Person: **DIEGO GUEVARA**;

Contact email: **hiperdaga7@gmail.com**.
"""

#!pip install codecarbon

!pip install -q open_clip_torch tqdm

import os
import zipfile
import urllib.request
import torch
import glob
import json
import xml.etree.ElementTree as ET
import concurrent.futures
from tqdm import tqdm
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import open_clip

# Section 1: Set up paths and download data
LOCAL_BASE_PATH = '/content/touche25_data'
os.makedirs(LOCAL_BASE_PATH, exist_ok=True)

ARGUMENTS_XML_URL = 'https://zenodo.org/records/15123526/files/arguments.xml?download=1'
ZIP_URL = 'https://zenodo.org/records/15123526/files/touche25-image-retrieval-and-generation-main.zip?download=1'

ARGUMENTS_XML_PATH = os.path.join(LOCAL_BASE_PATH, 'arguments.xml')
MAIN_ZIP_PATH = os.path.join(LOCAL_BASE_PATH, 'touche25-image-retrieval-and-generation-main.zip')
LOCAL_EXTRACT_PATH = os.path.join(LOCAL_BASE_PATH, 'touche25_main')
# Download arguments.xml if not present
if not os.path.exists(ARGUMENTS_XML_PATH):
    print("Downloading arguments.xml...")
    urllib.request.urlretrieve(ARGUMENTS_XML_URL, ARGUMENTS_XML_PATH)

# Download the main dataset zip if not present
if not os.path.exists(MAIN_ZIP_PATH):
    print("Downloading touche25-image-retrieval-and-generation-main.zip...")
    urllib.request.urlretrieve(ZIP_URL, MAIN_ZIP_PATH)

# Unzip dataset if not already extracted
if not os.path.exists(LOCAL_EXTRACT_PATH):
    print("Extracting the dataset...")
    with zipfile.ZipFile(MAIN_ZIP_PATH, 'r') as zip_ref:
        file_list = zip_ref.namelist()
        for file in tqdm(file_list, desc="Extracting files"):
            zip_ref.extract(file, LOCAL_EXTRACT_PATH)
else:
    print("Dataset already extracted.")

# Section 2: Load arguments
def load_arguments(xml_path):
    tree = ET.parse(xml_path)
    root = tree.getroot()
    return [{'id': arg.find('id').text, 'claim': arg.find('claim').text} for arg in root.findall('argument')]

arguments = load_arguments(ARGUMENTS_XML_PATH)
print(f"Loaded {len(arguments)} arguments")

# Section 3: start Track emissions
from codecarbon import EmissionsTracker

# Iniciar seguimiento
tracker = EmissionsTracker()
tracker.start()

# Section 4: Load image captions in parallel
def load_caption_file(caption_path):
    image_id = os.path.basename(os.path.dirname(caption_path))
    with open(caption_path, 'r', encoding='utf-8') as f:
        caption = f.read().strip()
    return image_id, caption

def load_captions_parallel(images_folder):
    captions = {}
    caption_paths = glob.glob(os.path.join(images_folder, 'I*', 'I*', 'image-caption.txt'))
    with concurrent.futures.ThreadPoolExecutor() as executor:
        for image_id, caption in executor.map(load_caption_file, caption_paths):
            captions[image_id] = caption
    return captions

captions = load_captions_parallel(os.path.join(LOCAL_EXTRACT_PATH, 'images'))
print(f"Loaded {len(captions)} captions")

# Section 5: Configure CLIP
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')
tokenizer = open_clip.get_tokenizer('ViT-B-32')
model = model.to(device)

# Section 6: Generate or load embeddings
def embed_texts(texts, batch_size=512):
    all_embeddings = []
    for i in tqdm(range(0, len(texts), batch_size), desc="Embedding texts"):
        batch = texts[i:i+batch_size]
        tokens = tokenizer(batch).to(device)
        with torch.no_grad():
            embeddings = model.encode_text(tokens)
            embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)
            all_embeddings.append(embeddings.cpu())
        torch.cuda.empty_cache()
    return torch.cat(all_embeddings, dim=0)

claims_emb_path = os.path.join(LOCAL_BASE_PATH, 'claim_embeddings.pt')
captions_emb_path = os.path.join(LOCAL_BASE_PATH, 'caption_embeddings.pt')

if os.path.exists(claims_emb_path) and os.path.exists(captions_emb_path):
    print("Loading saved embeddings...")
    claim_embeddings = torch.load(claims_emb_path)
    caption_embeddings = torch.load(captions_emb_path)
else:
    print("Generating embeddings...")
    claim_texts = [arg['claim'] for arg in arguments]
    caption_texts = list(captions.values())
    claim_embeddings = embed_texts(claim_texts, batch_size=512)
    caption_embeddings = embed_texts(caption_texts, batch_size=512)
    torch.save(claim_embeddings, claims_emb_path)
    torch.save(caption_embeddings, captions_emb_path)

# Section 7: Compute cosine similarities and retrieve top-K results
TOP_K = 10
caption_ids = list(captions.keys())
results = []

for idx, arg in enumerate(arguments):
    claim_emb = claim_embeddings[idx].unsqueeze(0)
    sims = F.cosine_similarity(claim_emb, caption_embeddings)
    topk = torch.topk(sims, k=TOP_K)
    for rank, index in enumerate(topk.indices.tolist(), start=1):
        results.append({
            "argument_id": arg['id'],
            "method": "retrieval",
            "image_id": caption_ids[index],
            "rank": rank,
            "tag": "CEDNAV-UTB; CLIP_Baseline"
        })

# Section 8: Save results in JSONL format
output_path = os.path.join(LOCAL_BASE_PATH, 'submission.jsonl')
with open(output_path, 'w', encoding='utf-8') as f:
    for item in results:
        f.write(json.dumps(item) + '\n')

print(f"Results saved to {output_path}")

# Section 9: Final Track emissions
emissions = tracker.stop()
print(f"Emisiones estimadas de CO₂: {emissions:.6f} kg")

# Section 9: Output verification
with open(output_path, 'r', encoding='utf-8') as f:
    results_loaded = [json.loads(line.strip()) for line in f]

print(f"Loaded {len(results_loaded)} entries from the output file")
print("Example entries:")
for i in range(min(3, len(results_loaded))):
    print(json.dumps(results_loaded[i], indent=2, ensure_ascii=False))