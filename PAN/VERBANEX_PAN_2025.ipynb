{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PAN 2025 - AI-Generated Text Classifier with RoBERTa\n",
    "\n",
    "This notebook implements a text classifier to detect AI-generated content using the RoBERTa model. The project includes data preprocessing, class balancing, data augmentation, and model training."
   ],
   "id": "660b891335dbdeee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Library Imports",
   "id": "6db5d094b2321fa8"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-06T01:58:46.293840Z",
     "start_time": "2025-07-06T01:58:46.274840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main libraries for data manipulation and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn libraries for balancing and metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Transformers and PyTorch libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Dataset Loading and Exploration",
   "id": "d02aca640a68fa1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T01:59:34.102333Z",
     "start_time": "2025-07-06T01:59:30.261750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the training dataset\n",
    "df = pd.read_csv(r'data/dat_train_v2.csv')\n",
    "\n",
    "# Explore basic dataset characteristics\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET EXPLORATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 30)\n",
    "print(\"FIRST 5 ROWS:\")\n",
    "print(\"=\" * 30)\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 30)\n",
    "print(\"CLASS DISTRIBUTION:\")\n",
    "print(\"=\" * 30)\n",
    "class_distribution = df['label'].value_counts().sort_index()\n",
    "print(class_distribution)\n",
    "\n",
    "# Calculate percentages\n",
    "total_samples = len(df)\n",
    "print(\"\\nPercentages by class:\")\n",
    "for label, count in class_distribution.items():\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"  Class {label}: {count:,} samples ({percentage:.2f}%)\")"
   ],
   "id": "85939a35887cd3ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATASET EXPLORATION\n",
      "==================================================\n",
      "Dataset shape: (288918, 2)\n",
      "Columns: ['text', 'label']\n",
      "\n",
      "==============================\n",
      "FIRST 5 ROWS:\n",
      "==============================\n",
      "                                                text  label\n",
      "0  Have you ever had to wait for something for a ...      4\n",
      "1  But now, things were not so simple._SEP_The gi...      3\n",
      "2  Dear Editor,  I am writing to express my opini...      4\n",
      "3  Humans once wielded formidable magical power. ...      4\n",
      "4  Here is a way that I had to be patient, and we...      4\n",
      "\n",
      "==============================\n",
      "CLASS DISTRIBUTION:\n",
      "==============================\n",
      "label\n",
      "0    75270\n",
      "1    95398\n",
      "2    91232\n",
      "3    10740\n",
      "4    14910\n",
      "5     1368\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages by class:\n",
      "  Class 0: 75,270 samples (26.05%)\n",
      "  Class 1: 95,398 samples (33.02%)\n",
      "  Class 2: 91,232 samples (31.58%)\n",
      "  Class 3: 10,740 samples (3.72%)\n",
      "  Class 4: 14,910 samples (5.16%)\n",
      "  Class 5: 1,368 samples (0.47%)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Tokenizer Initialization and Verification",
   "id": "ffaf14268e4b5c80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T01:59:59.823048Z",
     "start_time": "2025-07-06T01:59:59.097696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize RoBERTa tokenizer\n",
    "print(\"Initializing RoBERTa tokenizer...\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Verify tokenizer functionality with an example\n",
    "sample_text = df['text'].iloc[0]\n",
    "tokens = tokenizer(sample_text, truncation=True, max_length=512)\n",
    "\n",
    "print(\"Tokenizer initialized successfully\")\n",
    "print(f\"Example text: {sample_text[:100]}...\")\n",
    "print(f\"Number of tokens: {len(tokens['input_ids'])}\")\n",
    "print(f\"Tokenizer vocabulary: {tokenizer.vocab_size:,} tokens\")"
   ],
   "id": "9456bfb79bcef075",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RoBERTa tokenizer...\n",
      "Tokenizer initialized successfully\n",
      "Example text: Have you ever had to wait for something for a really long time? Like waiting for your favorite food ...\n",
      "Number of tokens: 230\n",
      "Tokenizer vocabulary: 50,265 tokens\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Class Distribution Analysis and Balancing Strategy",
   "id": "92dba77a6eb16016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:00:20.237437Z",
     "start_time": "2025-07-06T02:00:20.206436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_class_distribution(df):\n",
    "    \"\"\"\n",
    "    Analyzes class distribution and defines a balancing strategy.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset with 'text' and 'label' columns\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with target sizes for each class\n",
    "    \"\"\"\n",
    "    print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Separate dataset by classes\n",
    "    class_dfs = {}\n",
    "    for label in sorted(df['label'].unique()):\n",
    "        class_dfs[label] = df[df['label'] == label]\n",
    "        print(f\"  Class {label}: {len(class_dfs[label]):,} samples\")\n",
    "\n",
    "    # Define balancing strategy\n",
    "    target_sizes = {}\n",
    "    print(\"\\nBALANCING STRATEGY:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    for label, class_df in class_dfs.items():\n",
    "        current_size = len(class_df)\n",
    "\n",
    "        if current_size > 80000:\n",
    "            target_sizes[label] = 80000  # Undersample majority classes\n",
    "            action = \"UNDERSAMPLE\"\n",
    "        elif current_size < 10000:\n",
    "            target_sizes[label] = 10000  # Oversample minority classes\n",
    "            action = \"OVERSAMPLE\"\n",
    "        else:\n",
    "            target_sizes[label] = current_size  # Keep balanced classes\n",
    "            action = \"MAINTAIN\"\n",
    "\n",
    "        print(f\"  Class {label}: {current_size:,} → {target_sizes[label]:,} ({action})\")\n",
    "\n",
    "    return class_dfs, target_sizes\n",
    "\n",
    "# Execute analysis\n",
    "class_dfs, target_sizes = analyze_class_distribution(df)"
   ],
   "id": "b42d4fae397c187a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS DISTRIBUTION ANALYSIS\n",
      "==================================================\n",
      "  Class 0: 75,270 samples\n",
      "  Class 1: 95,398 samples\n",
      "  Class 2: 91,232 samples\n",
      "  Class 3: 10,740 samples\n",
      "  Class 4: 14,910 samples\n",
      "  Class 5: 1,368 samples\n",
      "\n",
      "BALANCING STRATEGY:\n",
      "------------------------------\n",
      "  Class 0: 75,270 → 75,270 (MAINTAIN)\n",
      "  Class 1: 95,398 → 80,000 (UNDERSAMPLE)\n",
      "  Class 2: 91,232 → 80,000 (UNDERSAMPLE)\n",
      "  Class 3: 10,740 → 10,740 (MAINTAIN)\n",
      "  Class 4: 14,910 → 14,910 (MAINTAIN)\n",
      "  Class 5: 1,368 → 10,000 (OVERSAMPLE)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Applying Balancing Techniques",
   "id": "44b43461e1d0099b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:00:43.487188Z",
     "start_time": "2025-07-06T02:00:43.426664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_resampling(class_dfs, target_sizes, random_state=42):\n",
    "    \"\"\"\n",
    "    Applies resampling techniques to balance classes.\n",
    "\n",
    "    Args:\n",
    "        class_dfs (dict): Dictionary with DataFrames by class\n",
    "        target_sizes (dict): Target sizes for each class\n",
    "        random_state (int): Seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Balanced dataset\n",
    "    \"\"\"\n",
    "    print(\"APPLYING BALANCING TECHNIQUES\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    resampled_dfs = []\n",
    "\n",
    "    for label, class_df in class_dfs.items():\n",
    "        target_size = target_sizes[label]\n",
    "        current_size = len(class_df)\n",
    "\n",
    "        if current_size > target_size:\n",
    "            # Undersample (reduce samples)\n",
    "            resampled_df = resample(\n",
    "                class_df,\n",
    "                n_samples=target_size,\n",
    "                replace=False,  # Without replacement\n",
    "                random_state=random_state\n",
    "            )\n",
    "            print(f\"Class {label}: Undersampled from {current_size:,} to {target_size:,}\")\n",
    "\n",
    "        elif current_size < target_size:\n",
    "            # Oversample (increase samples)\n",
    "            resampled_df = resample(\n",
    "                class_df,\n",
    "                n_samples=target_size,\n",
    "                replace=True,   # With replacement\n",
    "                random_state=random_state\n",
    "            )\n",
    "            print(f\"Class {label}: Oversampled from {current_size:,} to {target_size:,}\")\n",
    "\n",
    "        else:\n",
    "            # Keep the same\n",
    "            resampled_df = class_df\n",
    "            print(f\"Class {label}: Maintained at {current_size:,}\")\n",
    "\n",
    "        resampled_dfs.append(resampled_df)\n",
    "\n",
    "    # Combine all dataframes\n",
    "    df_balanced = pd.concat(resampled_dfs, ignore_index=True)\n",
    "\n",
    "    # Shuffle randomly\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nBalanced dataset created: {len(df_balanced):,} total samples\")\n",
    "    return df_balanced\n",
    "\n",
    "# Apply balancing\n",
    "df_balanced = apply_resampling(class_dfs, target_sizes)\n",
    "\n",
    "# Verify final distribution\n",
    "print(\"\\nFINAL DISTRIBUTION AFTER BALANCING:\")\n",
    "print(df_balanced['label'].value_counts().sort_index())"
   ],
   "id": "19a4361f27647251",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING BALANCING TECHNIQUES\n",
      "========================================\n",
      "Class 0: Maintained at 75,270\n",
      "Class 1: Undersampled from 95,398 to 80,000\n",
      "Class 2: Undersampled from 91,232 to 80,000\n",
      "Class 3: Maintained at 10,740\n",
      "Class 4: Maintained at 14,910\n",
      "Class 5: Oversampled from 1,368 to 10,000\n",
      "\n",
      "Balanced dataset created: 270,920 total samples\n",
      "\n",
      "FINAL DISTRIBUTION AFTER BALANCING:\n",
      "label\n",
      "0    75270\n",
      "1    80000\n",
      "2    80000\n",
      "3    10740\n",
      "4    14910\n",
      "5    10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Data Augmentation for Minority Classes",
   "id": "ecb03c1dd08dacb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:01:17.123563Z",
     "start_time": "2025-07-06T02:01:11.404405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def augment_text(text, num_augmentations=1):\n",
    "    \"\"\"\n",
    "    Applies text augmentation techniques to increase diversity.\n",
    "\n",
    "    Implemented techniques:\n",
    "    - Random word deletion\n",
    "    - Word position swapping\n",
    "    - Word duplication\n",
    "\n",
    "    Args:\n",
    "        text (str): Original text\n",
    "        num_augmentations (int): Number of augmentations to generate\n",
    "\n",
    "    Returns:\n",
    "        str: Augmented text\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "\n",
    "    if len(words) < 5:  # Very short texts are not augmented\n",
    "        return text\n",
    "\n",
    "    # Randomly select augmentation technique\n",
    "    aug_type = random.choice(['delete', 'swap', 'duplicate'])\n",
    "    aug_words = words.copy()\n",
    "\n",
    "    if aug_type == 'delete' and len(words) > 10:\n",
    "        # Randomly delete 10% of words\n",
    "        num_delete = max(1, int(len(words) * 0.1))\n",
    "        for _ in range(num_delete):\n",
    "            if len(aug_words) > 5:\n",
    "                idx = random.randint(0, len(aug_words)-1)\n",
    "                aug_words.pop(idx)\n",
    "\n",
    "    elif aug_type == 'swap' and len(words) > 2:\n",
    "        # Swap random words\n",
    "        num_swaps = max(1, int(len(words) * 0.1))\n",
    "        for _ in range(num_swaps):\n",
    "            idx1 = random.randint(0, len(aug_words)-1)\n",
    "            idx2 = random.randint(0, len(aug_words)-1)\n",
    "            aug_words[idx1], aug_words[idx2] = aug_words[idx2], aug_words[idx1]\n",
    "\n",
    "    elif aug_type == 'duplicate':\n",
    "        # Duplicate random words\n",
    "        if len(aug_words) > 0:\n",
    "            idx = random.randint(0, len(aug_words)-1)\n",
    "            aug_words.insert(idx, aug_words[idx])\n",
    "\n",
    "    return ' '.join(aug_words)\n",
    "\n",
    "def apply_data_augmentation(df_balanced, class_dfs, augmentation_prob=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Applies data augmentation to classes that were oversampled.\n",
    "\n",
    "    Args:\n",
    "        df_balanced (pd.DataFrame): Already balanced dataset\n",
    "        class_dfs (dict): Original DataFrames by class\n",
    "        augmentation_prob (float): Probability of augmenting a text\n",
    "        random_state (int): Seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with augmented data\n",
    "    \"\"\"\n",
    "    print(\"APPLYING DATA AUGMENTATION\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    # Set seed\n",
    "    random.seed(random_state)\n",
    "\n",
    "    # Identify minority classes (that were oversampled)\n",
    "    minority_classes = [label for label, df in class_dfs.items() if len(df) < 10000]\n",
    "    print(f\"Classes to augment: {minority_classes}\")\n",
    "\n",
    "    augmented_rows = []\n",
    "\n",
    "    # Apply augmentation with progress bar\n",
    "    for idx, row in tqdm(df_balanced.iterrows(), total=len(df_balanced), desc=\"Augmenting data\"):\n",
    "        if row['label'] in minority_classes and random.random() < augmentation_prob:\n",
    "            augmented_text = augment_text(row['text'])\n",
    "            augmented_rows.append({'text': augmented_text, 'label': row['label']})\n",
    "\n",
    "    # Add augmented rows to dataset\n",
    "    if augmented_rows:\n",
    "        df_augmented = pd.DataFrame(augmented_rows)\n",
    "        df_balanced = pd.concat([df_balanced, df_augmented], ignore_index=True)\n",
    "        print(f\"Added {len(augmented_rows):,} augmented texts\")\n",
    "\n",
    "        # Shuffle again\n",
    "        df_balanced = df_balanced.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"No augmented texts were added\")\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "# Apply augmentation\n",
    "df_balanced = apply_data_augmentation(df_balanced, class_dfs)\n",
    "\n",
    "# Show final distribution\n",
    "print(\"\\nFINAL DISTRIBUTION WITH AUGMENTATION:\")\n",
    "final_distribution = df_balanced['label'].value_counts().sort_index()\n",
    "print(final_distribution)"
   ],
   "id": "f2e8b1e81ed9df48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING DATA AUGMENTATION\n",
      "===================================\n",
      "Classes to augment: [np.int64(5)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting data: 100%|██████████| 270920/270920 [00:05<00:00, 47813.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5,048 augmented texts\n",
      "\n",
      "FINAL DISTRIBUTION WITH AUGMENTATION:\n",
      "label\n",
      "0    75270\n",
      "1    80000\n",
      "2    80000\n",
      "3    10740\n",
      "4    14910\n",
      "5    15048\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Saving Processed Dataset",
   "id": "3beb639fe325330d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:02:12.137153Z",
     "start_time": "2025-07-06T02:02:06.446795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the processed dataset\n",
    "output_filename = 'dataset_balanced_roberta.csv'\n",
    "df_balanced.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"DATASET SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"Filename: {output_filename}\")\n",
    "print(f\"Total samples: {len(df_balanced):,}\")\n",
    "print(f\"Final distribution:\")\n",
    "for label, count in df_balanced['label'].value_counts().sort_index().items():\n",
    "    print(f\"   Class {label}: {count:,} samples\")\n",
    "\n",
    "# Show a sample of the final dataset\n",
    "print(f\"\\nProcessed dataset sample:\")\n",
    "print(df_balanced.head(3))"
   ],
   "id": "5fc2a58ea5652bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET SAVED SUCCESSFULLY\n",
      "===================================\n",
      "Filename: dataset_balanced_roberta.csv\n",
      "Total samples: 275,968\n",
      "Final distribution:\n",
      "   Class 0: 75,270 samples\n",
      "   Class 1: 80,000 samples\n",
      "   Class 2: 80,000 samples\n",
      "   Class 3: 10,740 samples\n",
      "   Class 4: 14,910 samples\n",
      "   Class 5: 15,048 samples\n",
      "\n",
      "Processed dataset sample:\n",
      "                                                text  label\n",
      "0  The dangers of using a cellphone while driving...      2\n",
      "1  To understand this, it's helpful to start with...      1\n",
      "2  The concept of driverless cars may appear fun,...      1\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Data Preparation for Training",
   "id": "4097e7d25575b4ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:02:50.008925Z",
     "start_time": "2025-07-06T02:02:45.699069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_train_val_test_splits(df, test_size=0.2, val_size=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Complete dataset\n",
    "        test_size (float): Proportion for test+validation\n",
    "        val_size (float): Proportion of validation within test+val set\n",
    "        random_state (int): Seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_texts, val_texts, test_texts, train_labels, val_labels, test_labels)\n",
    "    \"\"\"\n",
    "    print(\"PREPARING DATA SPLITS\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    # First split: train vs (val + test)\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        df['text'].tolist(),\n",
    "        df['label'].tolist(),\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=df['label']\n",
    "    )\n",
    "\n",
    "    # Second split: val vs test\n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts,\n",
    "        temp_labels,\n",
    "        test_size=val_size,\n",
    "        random_state=random_state,\n",
    "        stratify=temp_labels\n",
    "    )\n",
    "\n",
    "    print(f\"Training: {len(train_texts):,} samples ({len(train_texts)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Validation: {len(val_texts):,} samples ({len(val_texts)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Test: {len(test_texts):,} samples ({len(test_texts)/len(df)*100:.1f}%)\")\n",
    "\n",
    "    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n",
    "\n",
    "# Reload the processed dataset\n",
    "df = pd.read_csv('dataset_balanced_roberta.csv')\n",
    "\n",
    "# Prepare splits\n",
    "train_texts, val_texts, test_texts, train_labels, val_labels, test_labels = prepare_train_val_test_splits(df)\n",
    "\n",
    "# Verify stratified distribution in each set\n",
    "print(\"\\nStratified distribution verification:\")\n",
    "for split_name, labels in [(\"Train\", train_labels), (\"Val\", val_labels), (\"Test\", test_labels)]:\n",
    "    distribution = pd.Series(labels).value_counts().sort_index()\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for label, count in distribution.items():\n",
    "        print(f\"  Class {label}: {count:,}\")"
   ],
   "id": "991dcbd659e2791",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING DATA SPLITS\n",
      "===================================\n",
      "Training: 220,774 samples (80.0%)\n",
      "Validation: 27,597 samples (10.0%)\n",
      "Test: 27,597 samples (10.0%)\n",
      "\n",
      "Stratified distribution verification:\n",
      "\n",
      "Train:\n",
      "  Class 0: 60,216\n",
      "  Class 1: 64,000\n",
      "  Class 2: 64,000\n",
      "  Class 3: 8,592\n",
      "  Class 4: 11,928\n",
      "  Class 5: 12,038\n",
      "\n",
      "Val:\n",
      "  Class 0: 7,527\n",
      "  Class 1: 8,000\n",
      "  Class 2: 8,000\n",
      "  Class 3: 1,074\n",
      "  Class 4: 1,491\n",
      "  Class 5: 1,505\n",
      "\n",
      "Test:\n",
      "  Class 0: 7,527\n",
      "  Class 1: 8,000\n",
      "  Class 2: 8,000\n",
      "  Class 3: 1,074\n",
      "  Class 4: 1,491\n",
      "  Class 5: 1,505\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Class Weights Calculation",
   "id": "52035496c331515b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:03:21.860977Z",
     "start_time": "2025-07-06T02:03:21.815978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_class_weights(df):\n",
    "    \"\"\"\n",
    "    Calculates class weights to handle residual imbalance.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset with class distribution\n",
    "\n",
    "    Returns:\n",
    "        tuple: (weights_dict, weights_tensor)\n",
    "    \"\"\"\n",
    "    print(\"CALCULATING CLASS WEIGHTS\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    # Get unique labels sorted\n",
    "    unique_labels = sorted(df['label'].unique())\n",
    "    unique_labels_array = np.array(unique_labels)\n",
    "\n",
    "    # Calculate balanced weights\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=unique_labels_array,\n",
    "        y=df['label'].values\n",
    "    )\n",
    "\n",
    "    # Create weights dictionary\n",
    "    weights_dict = {label: weight for label, weight in zip(unique_labels, class_weights)}\n",
    "\n",
    "    print(\"Calculated weights:\")\n",
    "    for label, weight in weights_dict.items():\n",
    "        count = df[df['label'] == label].shape[0]\n",
    "        print(f\"  Class {label}: weight = {weight:.4f}, samples = {count:,}\")\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "    print(f\"\\nWeights tensor: {weights_tensor}\")\n",
    "\n",
    "    return weights_dict, weights_tensor\n",
    "\n",
    "# Calculate weights\n",
    "weights_dict, weights_tensor = calculate_class_weights(df)"
   ],
   "id": "573247b44a5be095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALCULATING CLASS WEIGHTS\n",
      "==============================\n",
      "Calculated weights:\n",
      "  Class 0: weight = 0.6111, samples = 75,270\n",
      "  Class 1: weight = 0.5749, samples = 80,000\n",
      "  Class 2: weight = 0.5749, samples = 80,000\n",
      "  Class 3: weight = 4.2826, samples = 10,740\n",
      "  Class 4: weight = 3.0848, samples = 14,910\n",
      "  Class 5: weight = 3.0565, samples = 15,048\n",
      "\n",
      "Weights tensor: tensor([0.6111, 0.5749, 0.5749, 4.2826, 3.0848, 3.0565])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Custom Dataset Class",
   "id": "2f87f65a9fa655bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:03:44.941126Z",
     "start_time": "2025-07-06T02:03:44.910617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for text classification with RoBERTa.\n",
    "\n",
    "    Features:\n",
    "    - Automatic tokenization with truncation and padding\n",
    "    - Label to index mapping\n",
    "    - Compatible with PyTorch DataLoader\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of texts\n",
    "            labels (list): List of labels\n",
    "            tokenizer: Transformers tokenizer\n",
    "            max_length (int): Maximum sequence length\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Create label to index mapping\n",
    "        self.unique_labels = sorted(list(set(labels)))\n",
    "        self.label_to_id = {label: i for i, label in enumerate(self.unique_labels)}\n",
    "        self.id_to_label = {i: label for label, i in self.label_to_id.items()}\n",
    "\n",
    "        print(f\"Dataset created: {len(self.texts)} samples\")\n",
    "        print(f\"Label mapping: {self.label_to_id}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Gets a tokenized element from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Element index\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with input_ids, attention_mask, and labels\n",
    "        \"\"\"\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.label_to_id[label], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "print(\"CREATING CUSTOM DATASETS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "print(f\"Datasets created successfully\")"
   ],
   "id": "4905a5f1b0f19431",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING CUSTOM DATASETS\n",
      "===================================\n",
      "Dataset created: 220774 samples\n",
      "Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
      "Dataset created: 27597 samples\n",
      "Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
      "Dataset created: 27597 samples\n",
      "Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
      "Datasets created successfully\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. RoBERTa Model Configuration",
   "id": "f39a82edf575254d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:04:07.834612Z",
     "start_time": "2025-07-06T02:04:06.459938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_roberta_model(num_labels, model_name='roberta-base'):\n",
    "    \"\"\"\n",
    "    Configures RoBERTa model for sequence classification.\n",
    "\n",
    "    Args:\n",
    "        num_labels (int): Number of classes\n",
    "        model_name (str): Pre-trained model name\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, device)\n",
    "    \"\"\"\n",
    "    print(\"CONFIGURING ROBERTA MODEL\")\n",
    "    print(\"=\" * 32)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "        problem_type=\"single_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Configure device (GPU if available)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Model information\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Total parameters: {num_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Number of classes: {num_labels}\")\n",
    "\n",
    "    return model, device\n",
    "\n",
    "# Configure model\n",
    "unique_labels = sorted(df['label'].unique())\n",
    "model, device = setup_roberta_model(len(unique_labels))\n",
    "\n",
    "# Move weights tensor to device\n",
    "weights_tensor = weights_tensor.to(device)"
   ],
   "id": "688ef4de01fa0f2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURING ROBERTA MODEL\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Total parameters: 124,650,246\n",
      "Trainable parameters: 124,650,246\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Custom Trainer with Class Weights",
   "id": "120b1b7918ebedb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:04:32.471944Z",
     "start_time": "2025-07-06T02:04:32.457937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Custom trainer that includes class weights in the loss function.\n",
    "\n",
    "    This helps handle class imbalance by applying higher penalty\n",
    "    to incorrect predictions of minority classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the trainer with class weights.\n",
    "\n",
    "        Args:\n",
    "            class_weights (torch.Tensor): Tensor with weights for each class\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        print(f\"Trainer configured with class weights: {class_weights}\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Computes loss using class weights.\n",
    "\n",
    "        Args:\n",
    "            model: Classification model\n",
    "            inputs: Input batch\n",
    "            return_outputs: Whether to return model outputs\n",
    "            num_items_in_batch: Number of items in batch\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor or tuple: Loss (and outputs if return_outputs=True)\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Apply class weights in loss function\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics for the model.\n",
    "\n",
    "    Args:\n",
    "        eval_pred: Predictions and true labels\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with calculated metrics\n",
    "    \"\"\"\n",
    "    # Extract predictions\n",
    "    predictions = eval_pred.predictions[0] if isinstance(eval_pred.predictions, tuple) else eval_pred.predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(eval_pred.label_ids, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        eval_pred.label_ids,\n",
    "        predictions,\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    # F1 per individual class\n",
    "    _, _, f1_per_class, _ = precision_recall_fscore_support(\n",
    "        eval_pred.label_ids,\n",
    "        predictions,\n",
    "        average=None\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1,\n",
    "        'precision_weighted': precision,\n",
    "        'recall_weighted': recall,\n",
    "        'f1_per_class': f1_per_class.tolist()\n",
    "    }\n",
    "\n",
    "print(\"Training functions defined correctly\")"
   ],
   "id": "112adc4a193cc3ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined correctly\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 13. Training Arguments Configuration",
   "id": "6175b3dcd11e9053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:05:00.515379Z",
     "start_time": "2025-07-06T02:05:00.443325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_training_arguments(output_dir='./roberta-classifier', epochs=3, batch_size=64):\n",
    "    \"\"\"\n",
    "    Configures arguments for model training.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Directory to save the model\n",
    "        epochs (int): Number of training epochs\n",
    "        batch_size (int): Batch size\n",
    "\n",
    "    Returns:\n",
    "        TrainingArguments: Training configuration\n",
    "    \"\"\"\n",
    "    training_args = TrainingArguments(\n",
    "        # Directories\n",
    "        output_dir=output_dir,\n",
    "        logging_dir='./logs',\n",
    "\n",
    "        # Training configuration\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size + 32,  # Larger batch for evaluation\n",
    "\n",
    "        # Optimization\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-5,\n",
    "\n",
    "        # Logging and evaluation\n",
    "        logging_steps=500,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=1000,\n",
    "\n",
    "        # Model saving\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1000,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_weighted',\n",
    "        greater_is_better=True,\n",
    "\n",
    "        # Performance optimizations\n",
    "        fp16=True if torch.cuda.is_available() else False,\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_pin_memory=True,\n",
    "\n",
    "        # Avoid external logging\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    print(\"TRAINING CONFIGURATION\")\n",
    "    print(\"=\" * 33)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Batch size (train): {batch_size}\")\n",
    "    print(f\"Batch size (eval): {batch_size + 32}\")\n",
    "    print(f\"FP16: {training_args.fp16}\")\n",
    "    print(f\"Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "    return training_args\n",
    "\n",
    "# Configure training arguments\n",
    "training_args = setup_training_arguments()"
   ],
   "id": "86d3b30162a2830f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING CONFIGURATION\n",
      "=================================\n",
      "Output directory: ./roberta-classifier\n",
      "Epochs: 3\n",
      "Batch size (train): 64\n",
      "Batch size (eval): 96\n",
      "FP16: True\n",
      "Gradient checkpointing: True\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 14. Trainer Creation and Configuration",
   "id": "b5320273f92e1e1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:05:22.551299Z",
     "start_time": "2025-07-06T02:05:22.495313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create trainer with class weights\n",
    "print(\"CONFIGURING TRAINER\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=weights_tensor,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Trainer configured successfully\")\n",
    "print(f\"Model: {model.__class__.__name__}\")\n",
    "print(f\"Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation dataset: {len(val_dataset)} samples\")\n",
    "print(f\"Class weights applied: {len(weights_tensor)} classes\")"
   ],
   "id": "7b3efa6de65a1579",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURING TRAINER\n",
      "=========================\n",
      "Trainer configured with class weights: tensor([0.6111, 0.5749, 0.5749, 4.2826, 3.0848, 3.0565], device='cuda:0')\n",
      "Trainer configured successfully\n",
      "Model: RobertaForSequenceClassification\n",
      "Training dataset: 220774 samples\n",
      "Validation dataset: 27597 samples\n",
      "Class weights applied: 6 classes\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15. Model Training",
   "id": "8694693fddad0a53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T02:41:10.038076Z",
     "start_time": "2025-07-06T02:05:45.863362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(trainer, save_path='./roberta-classifier-final'):\n",
    "    \"\"\"\n",
    "    Trains the model and saves results.\n",
    "\n",
    "    Args:\n",
    "        trainer: Configured trainer\n",
    "        save_path (str): Path to save final model\n",
    "\n",
    "    Returns:\n",
    "        TrainOutput: Training results\n",
    "    \"\"\"\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\" * 26)\n",
    "    print(\"This process may take several hours...\")\n",
    "\n",
    "    try:\n",
    "        # Train the model\n",
    "        train_result = trainer.train()\n",
    "\n",
    "        # Save final model\n",
    "        trainer.save_model(save_path)\n",
    "        print(f\"Model saved at: {save_path}\")\n",
    "\n",
    "        # Show training metrics\n",
    "        print(\"\\nTRAINING RESULTS\")\n",
    "        print(\"=\" * 31)\n",
    "        print(f\"Final loss: {train_result.training_loss:.4f}\")\n",
    "        print(f\"Total steps: {train_result.global_step}\")\n",
    "        print(f\"Total time: {train_result.metrics.get('train_runtime', 'N/A')}\")\n",
    "\n",
    "        return train_result\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted by user\")\n",
    "        print(\"Saving current model state...\")\n",
    "        trainer.save_model(save_path + \"_interrupted\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Execute training\n",
    "train_result = train_model(trainer)"
   ],
   "id": "8fda9a2518cf04c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "==========================\n",
      "This process may take several hours...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1311' max='10350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1311/10350 35:20 < 4:03:59, 0.62 it/s, Epoch 0.38/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "      <th>F1 Per Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.238421</td>\n",
       "      <td>0.914991</td>\n",
       "      <td>0.915206</td>\n",
       "      <td>0.923297</td>\n",
       "      <td>0.914991</td>\n",
       "      <td>[0.9728190876431912, 0.8929073739200322, 0.9136189481017067, 0.8101167315175097, 0.7648970747562297, 0.9779286926994907]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training interrupted by user\n",
      "Saving current model state...\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 16. Model Evaluation",
   "id": "bdbfab55a888c3eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_model(trainer, test_dataset, id_to_label):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the test set.\n",
    "\n",
    "    Args:\n",
    "        trainer: Trained trainer\n",
    "        test_dataset: Test dataset\n",
    "        id_to_label: Index to label mapping\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"EVALUATING MODEL ON TEST SET\")\n",
    "    print(\"=\" * 41)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    eval_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "    # Get detailed predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "    y_true = predictions.label_ids\n",
    "\n",
    "    # Calculate per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None\n",
    "    )\n",
    "\n",
    "    print(\"GENERAL METRICS:\")\n",
    "    print(f\"  Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1-Score (weighted): {eval_results['eval_f1_weighted']:.4f}\")\n",
    "    print(f\"  Precision (weighted): {eval_results['eval_precision_weighted']:.4f}\")\n",
    "    print(f\"  Recall (weighted): {eval_results['eval_recall_weighted']:.4f}\")\n",
    "\n",
    "    print(\"\\nPER-CLASS METRICS:\")\n",
    "    for i, (p, r, f, s) in enumerate(zip(precision, recall, f1, support)):\n",
    "        class_label = id_to_label[i]\n",
    "        print(f\"  Class {class_label}: Precision={p:.3f}, Recall={r:.3f}, F1={f:.3f}, Support={s}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\nCONFUSION MATRIX:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    return eval_results\n",
    "\n",
    "# Evaluate model if training was successful\n",
    "if train_result is not None:\n",
    "    eval_results = evaluate_model(trainer, test_dataset, train_dataset.id_to_label)\n",
    "else:\n",
    "    print(\"Cannot evaluate: training not completed\")"
   ],
   "id": "5b6118c3fd7a00a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 17. Final Model Saving",
   "id": "ecc5ca0621878a76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_final_model(model, tokenizer, save_path=\"./RoBERTa_IA_Final\"):\n",
    "    \"\"\"\n",
    "    Saves the final model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        tokenizer: Used tokenizer\n",
    "        save_path (str): Save path\n",
    "    \"\"\"\n",
    "    print(\"SAVING FINAL MODEL\")\n",
    "    print(\"=\" * 24)\n",
    "\n",
    "    try:\n",
    "        # Save model and tokenizer\n",
    "        model.save_pretrained(save_path)\n",
    "        tokenizer.save_pretrained(save_path)\n",
    "\n",
    "        print(f\"Model saved successfully at: {save_path}\")\n",
    "        print(f\"Saved files:\")\n",
    "        print(f\"   - config.json\")\n",
    "        print(f\"   - pytorch_model.bin\")\n",
    "        print(f\"   - tokenizer_config.json\")\n",
    "        print(f\"   - vocab.json\")\n",
    "        print(f\"   - merges.txt\")\n",
    "\n",
    "        # Save additional information\n",
    "        model_info = {\n",
    "            'model_name': 'roberta-base',\n",
    "            'num_labels': len(train_dataset.unique_labels),\n",
    "            'label_mapping': train_dataset.label_to_id,\n",
    "            'training_samples': len(train_dataset),\n",
    "            'validation_samples': len(val_dataset),\n",
    "            'test_samples': len(test_dataset)\n",
    "        }\n",
    "\n",
    "        import json\n",
    "        with open(f\"{save_path}/model_info.json\", 'w') as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "\n",
    "        print(f\"   - model_info.json\")\n",
    "        print(\"Save completed!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving: {str(e)}\")\n",
    "\n",
    "# Save final model\n",
    "save_final_model(model, tokenizer)\n",
    "\n",
    "print(\"\\nPROCESS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 35)\n",
    "print(\"Project summary:\")\n",
    "print(f\"   - Original dataset: {len(df)} samples\")\n",
    "print(f\"   - Balanced dataset: {len(df_balanced)} samples\")\n",
    "print(f\"   - Classes: {len(train_dataset.unique_labels)}\")\n",
    "print(f\"   - Model: RoBERTa for AI text classification\")"
   ],
   "id": "9b85bcc02c628eb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
