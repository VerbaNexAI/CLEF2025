{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiCuD_zxbZtB",
        "outputId": "fffbf6e0-0e2c-4347-c11d-2307e3fbe740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/reto_life_clef/Modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU3rU64AcUiZ",
        "outputId": "3408d2f0-6a06-4604-cccc-c69c0ef57114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ColabNotebooks\n",
            "PlantCLEF\n",
            "PlantCLEF2025_pseudoquadrats_without_labels_complementary_training_set\n",
            "PlantCLEF2025_test_images\n",
            "pretrained_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model_path = '/content/drive/MyDrive/reto_life_clef/Modelo/pretrained_models/vit_base_patch14_reg4_dinov2_lvd142m_pc24_onlyclassifier_then_all/model_best.pth.tar'\n",
        "\n",
        "try:\n",
        "  model = torch.load(model_path, weights_only=False)\n",
        "  print(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: Archivo no encontrado en {model_path}. Verifica la ruta.\")\n",
        "except Exception as e:\n",
        "  print(f\"Error al cargar el modelo: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBkFMrKUcVJb",
        "outputId": "e8ca1b44-a3b5-41d8-b364-c7c7e1e3265c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Average only over the patches in which the species occurs"
      ],
      "metadata": {
        "id": "KT1C_fKZHmPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import ArgumentParser\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "import timm\n",
        "import torch"
      ],
      "metadata": {
        "id": "48TakXh6HiMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    image = \"/content/drive/MyDrive/reto_life_clef/Modelo/PlantCLEF2025_test_images\"\n",
        "    class_mapping = \"/content/drive/MyDrive/reto_life_clef/Modelo/pretrained_models/class_mapping.txt\"\n",
        "    species_mapping = \"/content/drive/MyDrive/reto_life_clef/Modelo/pretrained_models/species_id_to_name.txt\"\n",
        "    pretrained_path = \"/content/drive/MyDrive/reto_life_clef/Modelo/pretrained_models/vit_base_patch14_reg4_dinov2_lvd142m_pc24_onlyclassifier_then_all/model_best.pth.tar\"\n",
        "    device = \"cuda\"\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "HO5eeaN0gMo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_class_mapping(class_list_file):\n",
        "    \"\"\"Carga el mapping de índice de clase a ID de especie.\"\"\"\n",
        "    with open(class_list_file) as f:\n",
        "        class_index_to_class_name = {i: line.strip() for i, line in enumerate(f)}\n",
        "    return class_index_to_class_name"
      ],
      "metadata": {
        "id": "5cTEILCQgMrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_species_mapping(species_map_file):\n",
        "    \"\"\"Carga el mapping de ID de especie a nombre de especie.\"\"\"\n",
        "    df = pd.read_csv(species_map_file, sep=';', quoting=1, dtype={'species_id': str})\n",
        "    df = df.set_index('species_id')\n",
        "    return df['species'].to_dict()"
      ],
      "metadata": {
        "id": "V5eSla-5gMtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def split_image(image_path, filas= 4, cols= 2, output_prefix=\"parte\"):\n",
        "    \"\"\"\n",
        "      Divide the image into (rows x cols) equal parts and save\n",
        "      them as <output_prefix>_1.jpg … <output_prefix>_{rows*cols}.jpg\n",
        "    \"\"\"\n",
        "    imagen = Image.open(image_path)\n",
        "    ancho, alto = imagen.size\n",
        "\n",
        "    # Use the rows and cols parameters\n",
        "    ancho_parte = ancho // cols\n",
        "    alto_parte  = alto  // filas\n",
        "\n",
        "    contador = 1\n",
        "    for i in range(filas):\n",
        "        for j in range(cols):\n",
        "            izquierda = j * ancho_parte\n",
        "            superior  = i * alto_parte\n",
        "            derecha   = izquierda + ancho_parte\n",
        "            inferior  = superior  + alto_parte\n",
        "\n",
        "            parte = imagen.crop((izquierda, superior, derecha, inferior))\n",
        "            parte.save(f\"{output_prefix}_{contador}.jpg\")\n",
        "            contador += 1"
      ],
      "metadata": {
        "id": "Z2oeK9vcgMwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading mappings and model\n",
        "cid_to_spid = load_class_mapping(args.class_mapping)\n",
        "spid_to_sp  = load_species_mapping(args.species_mapping)\n",
        "device      = torch.device(args.device)\n",
        "\n",
        "model = timm.create_model(\n",
        "    'vit_base_patch14_reg4_dinov2.lvd142m',\n",
        "    pretrained=False,\n",
        "    num_classes=len(cid_to_spid),\n",
        "    checkpoint_path=args.pretrained_path\n",
        "    ).to(device).eval()\n",
        "\n",
        "data_config = timm.data.resolve_model_data_config(model)\n",
        "transforms  = timm.data.create_transform(**data_config, is_training=False)"
      ],
      "metadata": {
        "id": "HcVBD3VtgVsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Image directory\n",
        "test_dir = \"/content/drive/MyDrive/reto_life_clef/Modelo/PlantCLEF2025_test_images\"\n",
        "image_paths = sorted(glob.glob(os.path.join(test_dir, \"*.jpg\")))\n",
        "\n",
        "submission = []\n",
        "# Image-level progress bar\n",
        "for image_path in tqdm(image_paths, desc=\"Procesando imágenes\", unit=\"imagen\"):\n",
        "    quadrat_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    # Initializes accumulators\n",
        "    agg_probs, agg_counts = {}, {}\n",
        "\n",
        "    # Divide the image into patches\n",
        "    imagen = Image.open(image_path)\n",
        "    filas, cols = 4, 2\n",
        "    ancho, alto = imagen.size\n",
        "    pw, ph = ancho // cols, alto // filas\n",
        "\n",
        "    for i in range(filas):\n",
        "        for j in range(cols):\n",
        "            patch = imagen.crop((j*pw, i*ph, (j+1)*pw, (i+1)*ph))\n",
        "            tensor = transforms(patch).unsqueeze(0).to(device)\n",
        "            out = model(tensor)\n",
        "            top_p, top_i = torch.topk(out.softmax(dim=1) * 100, k=10)\n",
        "            probs = top_p.cpu().detach().numpy()[0]\n",
        "            idxs = top_i.cpu().detach().numpy()[0]\n",
        "            # Accumulate probabilities and counts by species\n",
        "            for p, cid in zip(probs, idxs):\n",
        "                spid = cid_to_spid[cid]\n",
        "                agg_probs[spid] = agg_probs.get(spid, 0.0) + float(p)\n",
        "                agg_counts[spid] = agg_counts.get(spid, 0) + 1\n",
        "\n",
        "    # Calculate average and filter > 5%\n",
        "    avg = {spid: agg_probs[spid]/agg_counts[spid]\n",
        "           for spid in agg_counts\n",
        "           if (agg_probs[spid]/agg_counts[spid]) > 5}\n",
        "\n",
        "    # Sort species by trust\n",
        "    species_ids = sorted(avg, key=avg.get, reverse=True)\n",
        "    species_str = f\"[[{', '.join(species_ids)}]]\" if species_ids else \"[[]]\"\n",
        "    submission.append([quadrat_id, species_str])\n",
        "\n",
        "# Save the result in CSV with quotes and without index\n",
        "df_sub = pd.DataFrame(submission, columns=[\"quadrat_id\", \"species_ids\"])\n",
        "df_sub.to_csv(\"predicciones.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "print(\"Predicciones listas\")"
      ],
      "metadata": {
        "id": "6ocnXXTGgMyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bda273-8642-42c2-8e7e-bf0edecce422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes: 100%|██████████| 2105/2105 [52:51<00:00,  1.51s/imagen]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones listas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}