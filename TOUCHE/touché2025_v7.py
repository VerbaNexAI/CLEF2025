# -*- coding: utf-8 -*-
"""Touché2025_V7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11HhJJcfZ87bkSmhzJzU32SjK8EbND57D

<img src="https://github.com/HIPERDAGA/EO-Target-Tracking/blob/main/LOGO_CEDNAV_02.gif?raw=true" width="200">
<img src="https://github.com/HIPERDAGA/EO-Target-Tracking/blob/main/firma_animada.gif?raw=true" width="320">

#**Image Retrieval/Generation for Arguments 2025**
Team: **Computer Vision UTB**;

Affiliation: **CEDNAV**;

Country: **COLOMBIA**;

Contact Person: **DIEGO GUEVARA**;

Contact email: **hiperdaga7@gmail.com**.
"""

!pip install codecarbon

# 1. Montar Google Drive
from google.colab import drive
import os
import zipfile
import torch
import glob
import json
import xml.etree.ElementTree as ET
import concurrent.futures
from tqdm import tqdm
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
!pip install -q open_clip_torch tqdm
import open_clip

# Montar Drive
drive.mount('/content/drive')

# 2. Definir rutas
DRIVE_BASE_PATH = '/content/drive/MyDrive/DATASET_TOUCHE_2025'
MAIN_ZIP_PATH = os.path.join(DRIVE_BASE_PATH, 'touche25-image-retrieval-and-generation-main.zip')
ARGUMENTS_XML_PATH = os.path.join(DRIVE_BASE_PATH, 'arguments.xml')
LOCAL_EXTRACT_PATH = '/content/touche25_main'

# 3. Descomprimir dataset
#if not os.path.exists(LOCAL_EXTRACT_PATH):
   # print("Copiando y descomprimiendo el dataset...")
    #local_zip_path = '/content/touche25_main.zip'
    #if not os.path.exists(local_zip_path):
    #    !cp "$MAIN_ZIP_PATH" "$local_zip_path"
    #with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:
    #    zip_ref.extractall(LOCAL_EXTRACT_PATH)
#else:
 #   print("El dataset ya está descomprimido.")

# 3. Descomprimir dataset
if not os.path.exists(LOCAL_EXTRACT_PATH):
    print("Copiando y descomprimiendo el dataset...")
    local_zip_path = '/content/touche25_main.zip'

    if not os.path.exists(local_zip_path):
        !cp "$MAIN_ZIP_PATH" "$local_zip_path"

    # Abrir el zip y extraer con barra de progreso
    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:
        file_list = zip_ref.namelist()
        for file in tqdm(file_list, desc="Descomprimiendo archivos"):
            zip_ref.extract(file, LOCAL_EXTRACT_PATH)
else:
    print("El dataset ya está descomprimido.")

#Importar y configurar CodeCarbon
from codecarbon import EmissionsTracker

# Iniciar seguimiento
tracker = EmissionsTracker()
tracker.start()

# 4. Cargar argumentos
def load_arguments(xml_path):
    tree = ET.parse(xml_path)
    root = tree.getroot()
    return [{'id': arg.find('id').text, 'claim': arg.find('claim').text} for arg in root.findall('argument')]

arguments = load_arguments(ARGUMENTS_XML_PATH)
print(f"Cargados {len(arguments)} argumentos")

# 5. Cargar captions con multiprocesamiento
def load_caption_file(caption_path):
    image_id = os.path.basename(os.path.dirname(caption_path))
    with open(caption_path, 'r', encoding='utf-8') as f:
        caption = f.read().strip()
    return image_id, caption

def load_captions_parallel(images_folder):
    captions = {}
    caption_paths = glob.glob(os.path.join(images_folder, 'I*', 'I*', 'image-caption.txt'))
    with concurrent.futures.ThreadPoolExecutor() as executor:
        for image_id, caption in executor.map(load_caption_file, caption_paths):
            captions[image_id] = caption
    return captions

captions = load_captions_parallel(os.path.join(LOCAL_EXTRACT_PATH, 'images'))
print(f"Cargados {len(captions)} captions")

# 6. Configurar CLIP


device = 'cuda' if torch.cuda.is_available() else 'cpu'
model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')
tokenizer = open_clip.get_tokenizer('ViT-B-32')
model = model.to(device)

# 7. Embedding de texto
def embed_texts(texts, batch_size=512):
    all_embeddings = []
    for i in tqdm(range(0, len(texts), batch_size), desc="Embeddiendo textos"):
        batch = texts[i:i+batch_size]
        tokens = tokenizer(batch).to(device)
        with torch.no_grad():
            embeddings = model.encode_text(tokens)
            embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)
            all_embeddings.append(embeddings.cpu())
        torch.cuda.empty_cache()
    return torch.cat(all_embeddings, dim=0)

# 8. Embedding o cargar embeddings
claims_emb_path = os.path.join(DRIVE_BASE_PATH, 'claim_embeddings.pt')
captions_emb_path = os.path.join(DRIVE_BASE_PATH, 'caption_embeddings.pt')

if os.path.exists(claims_emb_path) and os.path.exists(captions_emb_path):
    print("Cargando embeddings guardados...")
    claim_embeddings = torch.load(claims_emb_path)
    caption_embeddings = torch.load(captions_emb_path)
else:
    print("Generando embeddings...")
    claim_texts = [arg['claim'] for arg in arguments]
    caption_texts = list(captions.values())
    claim_embeddings = embed_texts(claim_texts, batch_size=512)
    caption_embeddings = embed_texts(caption_texts, batch_size=512)
    torch.save(claim_embeddings, claims_emb_path)
    torch.save(caption_embeddings, captions_emb_path)

caption_ids = list(captions.keys())

# 9. Calcular similitudes y top-k
TOP_K = 10
results = []
for idx, arg in enumerate(arguments):
    claim_emb = claim_embeddings[idx].unsqueeze(0)
    sims = F.cosine_similarity(claim_emb, caption_embeddings)
    topk = torch.topk(sims, k=TOP_K)
    for rank, index in enumerate(topk.indices.tolist(), start=1):
        results.append({
            "argument_id": arg['id'],
            "method": "retrieval",
            "image_id": caption_ids[index],
            "rank": rank,
            "tag": "CEDNAV-UTB; CLIP_Baseline"
        })

# 10. Guardar archivo JSONL
output_path = os.path.join(DRIVE_BASE_PATH, 'submission.jsonl')
with open(output_path, 'w', encoding='utf-8') as f:
    for item in results:
        f.write(json.dumps(item) + '\n')

print(f"Archivo de resultados guardado en {output_path}")

#final del rastreo
emissions = tracker.stop()
print(f"Emisiones estimadas de CO₂: {emissions:.6f} kg")

# 11. Verificación de salida
with open(output_path, 'r', encoding='utf-8') as f:
    results_loaded = [json.loads(line.strip()) for line in f]

print(f"Se cargaron {len(results_loaded)} entradas del archivo de envío")
print("Ejemplo:")
for i in range(min(3, len(results_loaded))):
    print(json.dumps(results_loaded[i], indent=2, ensure_ascii=False))